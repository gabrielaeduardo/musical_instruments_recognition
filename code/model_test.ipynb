{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing SVC model with new recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('..\\models\\scaler', 'rb'))\n",
    "svc = pickle.load(open('..\\models\\svc_model', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## audios aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe header\n",
    "\n",
    "header = 'filename rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('..\\\\data\\\\extracted_data\\\\test_aleatorio.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from audio data and save in csv file\n",
    "\n",
    "for i in ['trem', 'pedra', 'aspirador']:\n",
    "    for filename in os.listdir(f'../data/test_audio/{i}'):\n",
    "        songname = f'../data/test_audio/{i}/{filename}'\n",
    "        y, sr = librosa.load(songname, sr =44100)\n",
    "        rms = librosa.feature.rms(y=y), \n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {i}'\n",
    "        file = open('..\\\\data\\extracted_data\\\\test_aleatorio.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_aleatorio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.drop(columns = ['filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(scaler.transform(np.array(d, dtype = float)), index=d.index, columns=d.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades trem\n",
      "flu: 22.16%\n",
      "gel: 17.63%\n",
      "pia: 7.02%\n",
      "sax: 15.8%\n",
      "tru: 18.69%\n",
      "vio: 18.69%\n",
      "Probabilidades pedra\n",
      "flu: 20.7%\n",
      "gel: 15.62%\n",
      "pia: 6.43%\n",
      "sax: 17.56%\n",
      "tru: 19.51%\n",
      "vio: 20.18%\n",
      "Probabilidades aspirador\n",
      "flu: 18.18%\n",
      "gel: 12.49%\n",
      "pia: 5.9%\n",
      "sax: 19.61%\n",
      "tru: 21.94%\n",
      "vio: 21.89%\n"
     ]
    }
   ],
   "source": [
    "proba = svc.predict_proba(X)\n",
    "\n",
    "for i in range(0, len(proba)):\n",
    "    print('Probabilidades {}'.format(df.label[i]))\n",
    "    for j in range(0, len(svc.classes_)):\n",
    "        print('{}: {}%'.format(svc.classes_[j], round(proba[i][j]*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRMAS - test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe header\n",
    "\n",
    "header = 'rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "# header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('..\\\\data\\\\extracted_data\\\\test_p1.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.DataFrame(columns=['filename', 'labels'])\n",
    "for filename in os.listdir('../data/test_audio/IRMAS/Part1'):\n",
    "    if filename[-3:] == 'wav':\n",
    "        songname = f'../data/test_audio/IRMAS/Part1/{filename}'\n",
    "        y, sr = librosa.load(songname, sr =44100)\n",
    "        rms = librosa.feature.rms(y=y), \n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {i}'\n",
    "        file = open('..\\\\data\\extracted_data\\\\test_p1.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "    else:\n",
    "        label = list()\n",
    "        with open(f'../data/test_audio/IRMAS/Part1/{filename}') as fp:\n",
    "            for line in fp:\n",
    "                label.append(line.strip())\n",
    "        new_row = [filename, label]\n",
    "        df_test1.loc[len(df_test1)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.to_csv('..\\\\data\\\\extracted_data\\\\p1_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabis\\AppData\\Local\\Temp/ipykernel_11648/743736955.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df1 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p1.csv', index_col=False)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p1.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(scaler.transform(np.array(df1, dtype = float)), index=df1.index, columns=df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred1 = pd.DataFrame(columns=['predict', 'proba'])\n",
    "preds1 = svc.predict(X1)\n",
    "probas1 = svc.predict_proba(X1)\n",
    "for i in range(0, len(X1)):\n",
    "    new_row = [preds1[i], probas1[i].max()]\n",
    "    df_pred1.loc[len(df_pred1)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste1 = pd.concat([df_test1, df_pred1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(02) dont kill the whale-1.txt</td>\n",
       "      <td>[gel]</td>\n",
       "      <td>sax</td>\n",
       "      <td>0.546729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(02) dont kill the whale-15.txt</td>\n",
       "      <td>[gel, pia]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.860479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(02) dont kill the whale-2.txt</td>\n",
       "      <td>[gel, voi]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.592850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(02) dont kill the whale-4.txt</td>\n",
       "      <td>[gel]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.690951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(02) dont kill the whale-8.txt</td>\n",
       "      <td>[gel]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.628022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>pia</td>\n",
       "      <td>0.828793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>pia</td>\n",
       "      <td>0.858018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>pia</td>\n",
       "      <td>0.959204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>sax</td>\n",
       "      <td>0.748439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>[1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>pia</td>\n",
       "      <td>0.795975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename      labels predict  \\\n",
       "0                       (02) dont kill the whale-1.txt       [gel]     sax   \n",
       "5                      (02) dont kill the whale-15.txt  [gel, pia]     gel   \n",
       "6                       (02) dont kill the whale-2.txt  [gel, voi]     gel   \n",
       "8                       (02) dont kill the whale-4.txt       [gel]     gel   \n",
       "10                      (02) dont kill the whale-8.txt       [gel]     gel   \n",
       "..                                                 ...         ...     ...   \n",
       "801  [1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...       [gac]     pia   \n",
       "802  [1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...       [gac]     pia   \n",
       "803  [1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...       [gac]     pia   \n",
       "804  [1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...       [gac]     sax   \n",
       "806  [1] - 03 - Alexandre Lagoya - Canarios (Sanz)-...       [gac]     pia   \n",
       "\n",
       "        proba  \n",
       "0    0.546729  \n",
       "5    0.860479  \n",
       "6    0.592850  \n",
       "8    0.690951  \n",
       "10   0.628022  \n",
       "..        ...  \n",
       "801  0.828793  \n",
       "802  0.858018  \n",
       "803  0.959204  \n",
       "804  0.748439  \n",
       "806  0.795975  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste1[teste1.proba > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRMAS - test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe header\n",
    "\n",
    "header = 'rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "# header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('..\\\\data\\\\extracted_data\\\\test_p2.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.DataFrame(columns=['filename', 'labels'])\n",
    "\n",
    "for filename in os.listdir('../data/test_audio/IRMAS/IRTestingData-Part2'):\n",
    "    if filename[-3:] == 'wav':\n",
    "        songname = f'../data/test_audio/IRMAS/IRTestingData-Part2/{filename}'\n",
    "        y, sr = librosa.load(songname, sr =44100)\n",
    "        rms = librosa.feature.rms(y=y), \n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {i}'\n",
    "        file = open('..\\\\data\\extracted_data\\\\test_p2.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "    else:\n",
    "        label = list()\n",
    "        with open(f'../data/test_audio/IRMAS/IRTestingData-Part2/{filename}') as fp:\n",
    "            for line in fp:\n",
    "                label.append(line.strip())\n",
    "        new_row = [filename, label]\n",
    "        df_test2.loc[len(df_test2)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.to_csv('..\\\\data\\\\extracted_data\\\\p2_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabis\\AppData\\Local\\Temp/ipykernel_11648/2397922567.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df2 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p2.csv', index_col=False)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p2.csv', index_col=False)\n",
    "X3 = pd.DataFrame(scaler.transform(np.array(df2, dtype = float)), index=df2.index, columns=df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred2 = pd.DataFrame(columns=['predict', 'proba'])\n",
    "preds2 = svc.predict(X3)\n",
    "probas2 = svc.predict_proba(X3)\n",
    "for i in range(0, len(X3)):\n",
    "    new_row = [preds2[i], probas2[i].max()]\n",
    "    df_pred2.loc[len(df_pred2)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2 = pd.concat([df_test2, df_pred2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0050_10CC___I_M_NOT_IN_LOVE-1.txt</td>\n",
       "      <td>[gac, org]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.585035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0050_10CC___I_M_NOT_IN_LOVE-11.txt</td>\n",
       "      <td>[voi]</td>\n",
       "      <td>sax</td>\n",
       "      <td>0.606247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0050_10CC___I_M_NOT_IN_LOVE-13.txt</td>\n",
       "      <td>[gac, org, voi]</td>\n",
       "      <td>flu</td>\n",
       "      <td>0.523183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0050_10CC___I_M_NOT_IN_LOVE-17.txt</td>\n",
       "      <td>[gac, org, voi]</td>\n",
       "      <td>flu</td>\n",
       "      <td>0.591750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0050_10CC___I_M_NOT_IN_LOVE-20.txt</td>\n",
       "      <td>[gac, org]</td>\n",
       "      <td>flu</td>\n",
       "      <td>0.516993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>Yngwie Malmsteen - Gimme gimme gimme-9.txt</td>\n",
       "      <td>[gel, voi]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.874389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Zamfir - The Lonely Shepherd - 01 - The Lonely...</td>\n",
       "      <td>[flu, gac, tru]</td>\n",
       "      <td>tru</td>\n",
       "      <td>0.775219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Zamfir - The Lonely Shepherd - 01 - The Lonely...</td>\n",
       "      <td>[flu, gac]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.505312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>Zamfir - The Lonely Shepherd - 01 - The Lonely...</td>\n",
       "      <td>[gac]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.945330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>Zamfir - The Lonely Shepherd - 01 - The Lonely...</td>\n",
       "      <td>[flu, gac]</td>\n",
       "      <td>sax</td>\n",
       "      <td>0.544061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename           labels  \\\n",
       "0                     0050_10CC___I_M_NOT_IN_LOVE-1.txt       [gac, org]   \n",
       "1                    0050_10CC___I_M_NOT_IN_LOVE-11.txt            [voi]   \n",
       "2                    0050_10CC___I_M_NOT_IN_LOVE-13.txt  [gac, org, voi]   \n",
       "4                    0050_10CC___I_M_NOT_IN_LOVE-17.txt  [gac, org, voi]   \n",
       "6                    0050_10CC___I_M_NOT_IN_LOVE-20.txt       [gac, org]   \n",
       "...                                                 ...              ...   \n",
       "1286         Yngwie Malmsteen - Gimme gimme gimme-9.txt       [gel, voi]   \n",
       "1288  Zamfir - The Lonely Shepherd - 01 - The Lonely...  [flu, gac, tru]   \n",
       "1289  Zamfir - The Lonely Shepherd - 01 - The Lonely...       [flu, gac]   \n",
       "1295  Zamfir - The Lonely Shepherd - 01 - The Lonely...            [gac]   \n",
       "1296  Zamfir - The Lonely Shepherd - 01 - The Lonely...       [flu, gac]   \n",
       "\n",
       "     predict     proba  \n",
       "0        gel  0.585035  \n",
       "1        sax  0.606247  \n",
       "2        flu  0.523183  \n",
       "4        flu  0.591750  \n",
       "6        flu  0.516993  \n",
       "...      ...       ...  \n",
       "1286     gel  0.874389  \n",
       "1288     tru  0.775219  \n",
       "1289     vio  0.505312  \n",
       "1295     vio  0.945330  \n",
       "1296     sax  0.544061  \n",
       "\n",
       "[740 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste2[teste2.proba > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRMAS - test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe header\n",
    "\n",
    "header = 'rms spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "# header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('..\\\\data\\\\extracted_data\\\\test_p3.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3 = pd.DataFrame(columns=['filename', 'labels'])\n",
    "for filename in os.listdir('../data/test_audio/IRMAS/Part3'):\n",
    "    if filename[-3:] == 'wav':\n",
    "        songname = f'../data/test_audio/IRMAS/Part3/{filename}'\n",
    "        y, sr = librosa.load(songname, sr =44100)\n",
    "        rms = librosa.feature.rms(y=y), \n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {i}'\n",
    "        file = open('..\\\\data\\extracted_data\\\\test_p3.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "    else:\n",
    "        label = list()\n",
    "        with open(f'../data/test_audio/IRMAS/Part3/{filename}') as fp:\n",
    "            for line in fp:\n",
    "                label.append(line.strip())\n",
    "        new_row = [filename, label]\n",
    "        df_test3.loc[len(df_test3)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3.to_csv('..\\\\data\\\\extracted_data\\\\p3_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabis\\AppData\\Local\\Temp/ipykernel_11648/2619968765.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df3 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p3.csv', index_col=False)\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv('..\\\\data\\\\extracted_data\\\\test_p3.csv', index_col=False)\n",
    "X3 = pd.DataFrame(scaler.transform(np.array(df3, dtype = float)), index=df3.index, columns=df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred3 = pd.DataFrame(columns=['predict', 'proba'])\n",
    "preds3 = svc.predict(X3)\n",
    "probas3 = svc.predict_proba(X3)\n",
    "for i in range(0, len(X3)):\n",
    "    new_row = [preds3[i], probas3[i].max()]\n",
    "    df_pred3.loc[len(df_pred3)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste3 = pd.concat([df_test3, df_pred3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02 bwv 1068 air on g string-1.txt</td>\n",
       "      <td>[cel, vio]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.976910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02 bwv 1068 air on g string-10.txt</td>\n",
       "      <td>[cel, vio]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.889362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02 bwv 1068 air on g string-11.txt</td>\n",
       "      <td>[cel, vio]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.662857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02 bwv 1068 air on g string-12.txt</td>\n",
       "      <td>[cel, vio]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.800655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 bwv 1068 air on g string-13.txt</td>\n",
       "      <td>[cel, vio]</td>\n",
       "      <td>vio</td>\n",
       "      <td>0.839267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>14-god is an astronaut - all is violent, all i...</td>\n",
       "      <td>[org]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.991870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>14-god is an astronaut - all is violent, all i...</td>\n",
       "      <td>[org]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.998361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>14-god is an astronaut - all is violent, all i...</td>\n",
       "      <td>[gel, org]</td>\n",
       "      <td>tru</td>\n",
       "      <td>0.698028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>14-god is an astronaut - all is violent, all i...</td>\n",
       "      <td>[gel, org]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.648737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>14.  Boots Randolph - Yakety Sax-3.txt</td>\n",
       "      <td>[gac, sax]</td>\n",
       "      <td>gel</td>\n",
       "      <td>0.531719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename      labels predict  \\\n",
       "0                    02 bwv 1068 air on g string-1.txt  [cel, vio]     vio   \n",
       "1                   02 bwv 1068 air on g string-10.txt  [cel, vio]     vio   \n",
       "2                   02 bwv 1068 air on g string-11.txt  [cel, vio]     vio   \n",
       "3                   02 bwv 1068 air on g string-12.txt  [cel, vio]     vio   \n",
       "4                   02 bwv 1068 air on g string-13.txt  [cel, vio]     vio   \n",
       "..                                                 ...         ...     ...   \n",
       "757  14-god is an astronaut - all is violent, all i...       [org]     gel   \n",
       "758  14-god is an astronaut - all is violent, all i...       [org]     gel   \n",
       "760  14-god is an astronaut - all is violent, all i...  [gel, org]     tru   \n",
       "761  14-god is an astronaut - all is violent, all i...  [gel, org]     gel   \n",
       "764             14.  Boots Randolph - Yakety Sax-3.txt  [gac, sax]     gel   \n",
       "\n",
       "        proba  \n",
       "0    0.976910  \n",
       "1    0.889362  \n",
       "2    0.662857  \n",
       "3    0.800655  \n",
       "4    0.839267  \n",
       "..        ...  \n",
       "757  0.991870  \n",
       "758  0.998361  \n",
       "760  0.698028  \n",
       "761  0.648737  \n",
       "764  0.531719  \n",
       "\n",
       "[464 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste3[teste3.proba > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('sigproc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2f094f520a40638d175922eea0c637e1ea11d8d52ec53f8be98e74cb4db12f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
